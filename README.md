# csdn_crawl
a crawl specially designed for csdn recommendation page

You can simply run webspider.py directly to finish the whole procedure.
CSDN recommendation page can give you about 3000 different pages and update about 250 pages at 30 o'clock every hour.
This crawl will automatically fetch pages until the number reaches the requirement.
Pages are automatically deduplicated so that you will not fetch the same page twice.

#Warning
You have to obey csdn's robot.txt to prevent legal risk!
